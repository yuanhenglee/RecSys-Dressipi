{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import csv\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_root_path = '/content/drive/MyDrive/NCCU1102/WSM/proj3/RecSys-Dressipi/'\n",
    "project_root_path = '../..'\n",
    "n_train_sample = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model( i ):\n",
    "    # fit training data\n",
    "    X_path = project_root_path + '/dataset/train_features/train_X_' + str(i) + '.pickle'\n",
    "    y_path = project_root_path + '/dataset/train_features/train_y_' + str(i) + '.pickle'\n",
    "    with open( X_path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    with open( y_path, 'rb') as f:\n",
    "        y = pickle.load(f)\n",
    "\n",
    "    query_train = [n_train_sample] * (len(X)//n_train_sample)\n",
    "\n",
    "    print(\"Starting training... train_\" + str(i) )\n",
    "    start_time = time.time()\n",
    "    gbm = lgb.LGBMRanker(device = 'gpu')\n",
    "    if i == 0:\n",
    "        gbm.fit(X, y, group=query_train)\n",
    "    else:\n",
    "        gbm.fit(X, y, group=query_train, init_model='../../model/lgbm_gpu/lgbm_' + str(i-1))\n",
    "    gbm.booster_.save_model('../../model/lgbm_gpu/lgbm_' + str(i))\n",
    "    print(\"Training finished \" + str(time.time() - start_time))\n",
    "    \n",
    "    return gbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MRR( X_sessions, y_sessions, bst ):\n",
    "    score = []\n",
    "    for X, y in zip( X_sessions, y_sessions ):\n",
    "        pred = bst.predict(X)\n",
    "        top100_index = np.argsort(pred)[-100:]\n",
    "        rank_result = []\n",
    "        flag = False\n",
    "        for count, index in enumerate(top100_index[::-1]):\n",
    "            if y[index] == 1:\n",
    "                score.append(1/(count+1))\n",
    "                flag = True\n",
    "                break\n",
    "        if not flag:\n",
    "            score.append(0)\n",
    "    return np.mean(score)\n",
    "\n",
    "def pred2rank_result( session_id, X, pred ):\n",
    "    top100_index = np.argsort(pred)[-100:]\n",
    "    rank_result = []\n",
    "    for count, index in enumerate(top100_index[::-1]):\n",
    "        row = ','.join([str(session_id), str(int(X[index][0])), str(count+1)])\n",
    "        rank_result.append(row)\n",
    "    return rank_result\n",
    "\n",
    "def predict_session( gbm, session_id ):\n",
    "    with open('../../dataset/test_features/test_X_' + str(session_id) + '.pickle', 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    pred = gbm.predict(X)\n",
    "    return pred2rank_result( session_id, X, pred )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training... train_0\n",
      "Training finished 10.134701251983643\n",
      "Starting training... train_1\n",
      "Training finished 10.276913404464722\n",
      "Starting training... train_2\n",
      "Training finished 11.178255558013916\n",
      "Starting training... train_3\n",
      "Training finished 12.348575115203857\n",
      "Starting training... train_4\n",
      "Training finished 13.534945726394653\n",
      "Starting training... train_5\n",
      "Training finished 14.866919755935669\n",
      "Starting training... train_6\n",
      "Training finished 16.920180320739746\n",
      "Starting training... train_7\n",
      "Training finished 19.29195523262024\n",
      "Starting training... train_8\n",
      "Training finished 3.858412981033325\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,9):\n",
    "    model = train_model( i )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39531558829031727\n",
      "0.4150499200580192\n",
      "0.4007683544416681\n",
      "0.406037735229362\n",
      "0.4029493822656246\n",
      "0.40126911153904177\n",
      "0.4019283576651242\n",
      "0.4072011974154905\n",
      "0.513792690531054\n",
      "CPU times: user 31min 43s, sys: 3.95 s, total: 31min 47s\n",
      "Wall time: 3min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "bst = lgb.Booster(model_file='../../model/lgbm_gpu/lgbm_8')\n",
    "for validate_id in range(9):\n",
    "    # fit training data\n",
    "    X_path = project_root_path + '/dataset/train_features/train_X_' + str(validate_id) + '.pickle'\n",
    "    y_path = project_root_path + '/dataset/train_features/train_y_' + str(validate_id) + '.pickle'\n",
    "    with open( X_path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    with open( y_path, 'rb') as f:\n",
    "        y = pickle.load(f)\n",
    "\n",
    "    X_sessions = np.array_split(X, len(X)//n_train_sample)\n",
    "    y_sessions = np.array_split(y, len(y)//n_train_sample)\n",
    "    print(MRR( X_sessions, y_sessions, bst))\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7f073b11ca30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst = lgb.Booster(model_file='../../model/lgbm_gpu/lgbm_8')\n",
    "bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [02:07<00:00, 392.81it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "with open('../../dataset/test_leaderboard_uniq_sessions') as f:\n",
    "    for line in tqdm(f.readlines()[1:]):\n",
    "        session_id = int(line) \n",
    "        results.extend(predict_session(bst, session_id ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../result/lgbm_train_gpu_8.csv', 'w') as f:\n",
    "    f.write('session_id,item_id,rank\\n')\n",
    "    f.write('\\n'.join(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
