{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import gc\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_root_path = '/content/drive/MyDrive/NCCU1102/WSM/proj3/RecSys-Dressipi/'\n",
    "project_root_path = '../..'\n",
    "n_train_sample = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model( i ):\n",
    "    # fit training data\n",
    "    X_path = project_root_path + '/dataset/train_features/train_X_' + str(i) + '.pickle'\n",
    "    y_path = project_root_path + '/dataset/train_features/train_y_' + str(i) + '.pickle'\n",
    "    with open( X_path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    with open( y_path, 'rb') as f:\n",
    "        y = pickle.load(f)\n",
    "\n",
    "    query_train = [n_train_sample] * (len(X)//n_train_sample)\n",
    "\n",
    "    print(\"Starting training... train_\" + str(i) )\n",
    "    start_time = time.time()\n",
    "    gbm = lgb.LGBMRanker(device = 'cpu')\n",
    "    if i == 0:\n",
    "        gbm.fit(X, y, group=query_train)\n",
    "    else:\n",
    "        gbm.fit(X, y, group=query_train, init_model='../../model/lgbm/lgbm_' + str(i-1))\n",
    "    gbm.booster_.save_model('../../model/lgbm/lgbm_' + str(i))\n",
    "    print(\"Training finished \" + str(time.time() - start_time))\n",
    "    \n",
    "    return gbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MRR( X_sessions, y_sessions, y_preds ):\n",
    "    score = []\n",
    "    for X, y, pred in zip( X_sessions, y_sessions, y_preds ):\n",
    "        top100_index = np.argsort(pred)[-100:]\n",
    "        rank_result = []\n",
    "        flag = False\n",
    "        for count, index in enumerate(top100_index[::-1]):\n",
    "            if y[index] == 1:\n",
    "                score.append(1/(count+1))\n",
    "                flag = True\n",
    "                break\n",
    "        if not flag:\n",
    "            score.append(0)\n",
    "    return np.mean(score)\n",
    "\n",
    "def pred2rank_result( session_id, X, pred ):\n",
    "    top100_index = np.argsort(pred)[-100:]\n",
    "    rank_result = []\n",
    "    for count, index in enumerate(top100_index[::-1]):\n",
    "        row = ','.join([str(session_id), str(int(X[index][0])), str(count+1)])\n",
    "        rank_result.append(row)\n",
    "    return rank_result\n",
    "\n",
    "def predict_session( gbm, session_id ):\n",
    "    with open('../../dataset/test_features/test_X_' + str(session_id) + '.pickle', 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    pred = gbm.predict(X)\n",
    "    return pred2rank_result( session_id, X, pred )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training... train_8\n",
      "Training finished 24.394206285476685\n",
      "Starting training... train_9\n",
      "Training finished 25.47046160697937\n",
      "Starting training... train_10\n",
      "Training finished 28.998876571655273\n",
      "Starting training... train_11\n",
      "Training finished 31.131080150604248\n",
      "Starting training... train_12\n",
      "Training finished 34.38035750389099\n",
      "Starting training... train_13\n",
      "Training finished 37.90410280227661\n",
      "Starting training... train_14\n",
      "Training finished 40.752618074417114\n",
      "Starting training... train_15\n",
      "Training finished 43.408037424087524\n",
      "Starting training... train_16\n",
      "Training finished 47.432823181152344\n",
      "Starting training... train_17\n",
      "Training finished 49.918471336364746\n",
      "Starting training... train_18\n",
      "Training finished 53.49655604362488\n",
      "Starting training... train_19\n",
      "Training finished 55.99709963798523\n",
      "Starting training... train_20\n",
      "Training finished 60.53599667549133\n",
      "Starting training... train_21\n",
      "Training finished 63.06070685386658\n",
      "Starting training... train_22\n",
      "Training finished 67.45344948768616\n",
      "Starting training... train_23\n",
      "Training finished 69.61440420150757\n",
      "Starting training... train_24\n",
      "Training finished 72.9702467918396\n",
      "Starting training... train_25\n",
      "Training finished 74.99055337905884\n",
      "Starting training... train_26\n",
      "Training finished 80.00218105316162\n",
      "Starting training... train_27\n",
      "Training finished 82.57776117324829\n",
      "Starting training... train_28\n",
      "Training finished 86.02419781684875\n",
      "Starting training... train_29\n",
      "Training finished 89.07547283172607\n",
      "Starting training... train_30\n",
      "Training finished 94.4079864025116\n",
      "Starting training... train_31\n",
      "Training finished 28.05680203437805\n"
     ]
    }
   ],
   "source": [
    "for i in range(8,32):\n",
    "    model = train_model( i )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46994645260165346\n",
      "0.4689435812922673\n",
      "CPU times: user 42min 2s, sys: 4.21 s, total: 42min 6s\n",
      "Wall time: 3min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bst = lgb.Booster(model_file='../../model/lgbm/lgbm_31')\n",
    "for validate_id in range(8,10):\n",
    "    # fit training data\n",
    "    X_path = project_root_path + '/dataset/train_features/train_X_' + str(validate_id) + '.pickle'\n",
    "    y_path = project_root_path + '/dataset/train_features/train_y_' + str(validate_id) + '.pickle'\n",
    "    with open( X_path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    with open( y_path, 'rb') as f:\n",
    "        y = pickle.load(f)\n",
    "\n",
    "    X_sessions = np.array_split(X, len(X)//n_train_sample)\n",
    "    y_sessions = np.array_split(y, len(y)//n_train_sample)\n",
    "\n",
    "    del X\n",
    "    del y\n",
    "    gc.collect()\n",
    "\n",
    "    y_preds = [bst.predict(X_session) for X_session in X_sessions]\n",
    "    print(MRR( X_sessions, y_sessions, y_preds))\n",
    "    del X_sessions\n",
    "    del y_sessions\n",
    "    del y_preds\n",
    "    gc.collect()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7f258727c160>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst = lgb.Booster(model_file='../../model/lgbm/lgbm_31')\n",
    "bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [09:42<00:00, 85.90it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "with open('../../dataset/test_leaderboard_uniq_sessions') as f:\n",
    "    for line in tqdm(f.readlines()[1:]):\n",
    "        session_id = int(line) \n",
    "        results.extend(predict_session(bst, session_id ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../result/lgbm_train31_2021.csv', 'w') as f:\n",
    "    f.write('session_id,item_id,rank\\n')\n",
    "    f.write('\\n'.join(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
