{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import csv\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_root_path = '/content/drive/MyDrive/NCCU1102/WSM/proj3/RecSys-Dressipi/'\n",
    "project_root_path = '../..'\n",
    "n_train_sample = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model( i ):\n",
    "    # fit training data\n",
    "    X_path = project_root_path + '/dataset/train_features/train_X_' + str(i) + '.pickle'\n",
    "    y_path = project_root_path + '/dataset/train_features/train_y_' + str(i) + '.pickle'\n",
    "    with open( X_path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    with open( y_path, 'rb') as f:\n",
    "        y = pickle.load(f)\n",
    "\n",
    "    query_train = [n_train_sample] * (len(X)//n_train_sample) + [len(X)]\n",
    "\n",
    "    print(\"Starting training... train_\" + str(i) )\n",
    "    start_time = time.time()\n",
    "    gbm = lgb.LGBMRanker()\n",
    "    if i == 0:\n",
    "        gbm.fit(X, y, group=query_train)\n",
    "    else:\n",
    "        gbm.fit(X, y, group=query_train, init_model='../../model/lgbm_' + str(i-1))\n",
    "    gbm.booster_.save_model('../../model/lgbm_' + str(i))\n",
    "    print(\"Training finished \" + str(time.time() - start_time))\n",
    "    \n",
    "    return gbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MRR( X_sessions, y_sessions, bst ):\n",
    "    score = []\n",
    "    for X, y in zip( X_sessions, y_sessions ):\n",
    "        pred = bst.predict(X)\n",
    "        top100_index = np.argsort(pred)[-100:]\n",
    "        rank_result = []\n",
    "        flag = False\n",
    "        for count, index in enumerate(top100_index[::-1]):\n",
    "            if y[index] == 1:\n",
    "                score.append(1/(count+1))\n",
    "                flag = True\n",
    "                break\n",
    "        if not flag:\n",
    "            score.append(0)\n",
    "    return np.mean(score)\n",
    "\n",
    "def pred2rank_result( session_id, X, pred ):\n",
    "    top100_index = np.argsort(pred)[-100:]\n",
    "    rank_result = []\n",
    "    for count, index in enumerate(top100_index[::-1]):\n",
    "        row = ','.join([str(session_id), str(int(X[index][0])), str(count+1)])\n",
    "        rank_result.append(row)\n",
    "    return rank_result\n",
    "\n",
    "def predict_session( gbm, session_id ):\n",
    "    with open('../../dataset/test_features/test_X_' + str(session_id) + '.pickle', 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    pred = gbm.predict(X)\n",
    "    return pred2rank_result( session_id, X, pred )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training... train_0\n",
      "Training finished 2.4499361515045166\n",
      "Starting training... train_1\n",
      "Training finished 2.8307156562805176\n",
      "Starting training... train_2\n",
      "Training finished 3.1501870155334473\n",
      "Starting training... train_3\n",
      "Training finished 3.474064826965332\n",
      "Starting training... train_4\n",
      "Training finished 3.995468854904175\n",
      "Starting training... train_5\n",
      "Training finished 4.4232497215271\n",
      "Starting training... train_6\n",
      "Training finished 5.115475177764893\n",
      "Starting training... train_7\n",
      "Training finished 6.272687196731567\n",
      "Starting training... train_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Sum of query counts is not same with #data\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Sum of query counts is not same with #data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/home/yhl/Documents/code/RecSys-Dressipi/src/supervised_learning/lgbm.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/yhl/Documents/code/RecSys-Dressipi/src/supervised_learning/lgbm.ipynb#ch0000005?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39m9\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/yhl/Documents/code/RecSys-Dressipi/src/supervised_learning/lgbm.ipynb#ch0000005?line=1'>2</a>\u001b[0m     model \u001b[39m=\u001b[39m train_model( i )\n",
      "\u001b[1;32m/home/yhl/Documents/code/RecSys-Dressipi/src/supervised_learning/lgbm.ipynb Cell 3'\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yhl/Documents/code/RecSys-Dressipi/src/supervised_learning/lgbm.ipynb#ch0000002?line=15'>16</a>\u001b[0m     gbm\u001b[39m.\u001b[39mfit(X, y, group\u001b[39m=\u001b[39mquery_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yhl/Documents/code/RecSys-Dressipi/src/supervised_learning/lgbm.ipynb#ch0000002?line=16'>17</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/yhl/Documents/code/RecSys-Dressipi/src/supervised_learning/lgbm.ipynb#ch0000002?line=17'>18</a>\u001b[0m     gbm\u001b[39m.\u001b[39;49mfit(X, y, group\u001b[39m=\u001b[39;49mquery_train, init_model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m../../model/lgbm_\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39mstr\u001b[39;49m(i\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yhl/Documents/code/RecSys-Dressipi/src/supervised_learning/lgbm.ipynb#ch0000002?line=18'>19</a>\u001b[0m gbm\u001b[39m.\u001b[39mbooster_\u001b[39m.\u001b[39msave_model(\u001b[39m'\u001b[39m\u001b[39m../../model/lgbm_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(i))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yhl/Documents/code/RecSys-Dressipi/src/supervised_learning/lgbm.ipynb#ch0000002?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTraining finished \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:1067\u001b[0m, in \u001b[0;36mLGBMRanker.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_group, eval_metric, eval_at, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mShould set group for all eval datasets for ranking task; \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1064\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39mif you use dict, the index should start from 0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1066\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_at \u001b[39m=\u001b[39m eval_at\n\u001b[0;32m-> 1067\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49msample_weight, init_score\u001b[39m=\u001b[39;49minit_score, group\u001b[39m=\u001b[39;49mgroup,\n\u001b[1;32m   1068\u001b[0m             eval_set\u001b[39m=\u001b[39;49meval_set, eval_names\u001b[39m=\u001b[39;49meval_names, eval_sample_weight\u001b[39m=\u001b[39;49meval_sample_weight,\n\u001b[1;32m   1069\u001b[0m             eval_init_score\u001b[39m=\u001b[39;49meval_init_score, eval_group\u001b[39m=\u001b[39;49meval_group, eval_metric\u001b[39m=\u001b[39;49meval_metric,\n\u001b[1;32m   1070\u001b[0m             early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds, verbose\u001b[39m=\u001b[39;49mverbose, feature_name\u001b[39m=\u001b[39;49mfeature_name,\n\u001b[1;32m   1071\u001b[0m             categorical_feature\u001b[39m=\u001b[39;49mcategorical_feature, callbacks\u001b[39m=\u001b[39;49mcallbacks, init_model\u001b[39m=\u001b[39;49minit_model)\n\u001b[1;32m   1072\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:748\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    745\u001b[0m evals_result \u001b[39m=\u001b[39m {}\n\u001b[1;32m    746\u001b[0m callbacks\u001b[39m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 748\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m    749\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    750\u001b[0m     train_set\u001b[39m=\u001b[39;49mtrain_set,\n\u001b[1;32m    751\u001b[0m     num_boost_round\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_estimators,\n\u001b[1;32m    752\u001b[0m     valid_sets\u001b[39m=\u001b[39;49mvalid_sets,\n\u001b[1;32m    753\u001b[0m     valid_names\u001b[39m=\u001b[39;49meval_names,\n\u001b[1;32m    754\u001b[0m     fobj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fobj,\n\u001b[1;32m    755\u001b[0m     feval\u001b[39m=\u001b[39;49meval_metrics_callable,\n\u001b[1;32m    756\u001b[0m     init_model\u001b[39m=\u001b[39;49minit_model,\n\u001b[1;32m    757\u001b[0m     feature_name\u001b[39m=\u001b[39;49mfeature_name,\n\u001b[1;32m    758\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks\n\u001b[1;32m    759\u001b[0m )\n\u001b[1;32m    761\u001b[0m \u001b[39mif\u001b[39;00m evals_result:\n\u001b[1;32m    762\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evals_result \u001b[39m=\u001b[39m evals_result\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:271\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39m# construct booster\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m     booster \u001b[39m=\u001b[39m Booster(params\u001b[39m=\u001b[39;49mparams, train_set\u001b[39m=\u001b[39;49mtrain_set)\n\u001b[1;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m is_valid_contain_train:\n\u001b[1;32m    273\u001b[0m         booster\u001b[39m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:2605\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[0;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[1;32m   2598\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_network(\n\u001b[1;32m   2599\u001b[0m         machines\u001b[39m=\u001b[39mmachines,\n\u001b[1;32m   2600\u001b[0m         local_listen_port\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mlocal_listen_port\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   2601\u001b[0m         listen_time_out\u001b[39m=\u001b[39mparams\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_out\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m120\u001b[39m),\n\u001b[1;32m   2602\u001b[0m         num_machines\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mnum_machines\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   2603\u001b[0m     )\n\u001b[1;32m   2604\u001b[0m \u001b[39m# construct booster object\u001b[39;00m\n\u001b[0;32m-> 2605\u001b[0m train_set\u001b[39m.\u001b[39;49mconstruct()\n\u001b[1;32m   2606\u001b[0m \u001b[39m# copy the parameters from train_set\u001b[39;00m\n\u001b[1;32m   2607\u001b[0m params\u001b[39m.\u001b[39mupdate(train_set\u001b[39m.\u001b[39mget_params())\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1815\u001b[0m, in \u001b[0;36mDataset.construct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1812\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_init_score_by_predictor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predictor, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, used_indices)\n\u001b[1;32m   1813\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1814\u001b[0m     \u001b[39m# create train\u001b[39;00m\n\u001b[0;32m-> 1815\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lazy_init(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata, label\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel,\n\u001b[1;32m   1816\u001b[0m                     weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, group\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroup,\n\u001b[1;32m   1817\u001b[0m                     init_score\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_score, predictor\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predictor,\n\u001b[1;32m   1818\u001b[0m                     silent\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msilent, feature_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_name,\n\u001b[1;32m   1819\u001b[0m                     categorical_feature\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcategorical_feature, params\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams)\n\u001b[1;32m   1820\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfree_raw_data:\n\u001b[1;32m   1821\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1563\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_weight(weight)\n\u001b[1;32m   1562\u001b[0m \u001b[39mif\u001b[39;00m group \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1563\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_group(group)\n\u001b[1;32m   1564\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(predictor, _InnerPredictor):\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predictor \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m init_score \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:2229\u001b[0m, in \u001b[0;36mDataset.set_group\u001b[0;34m(self, group)\u001b[0m\n\u001b[1;32m   2227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m group \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2228\u001b[0m     group \u001b[39m=\u001b[39m list_to_1d_numpy(group, np\u001b[39m.\u001b[39mint32, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgroup\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 2229\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_field(\u001b[39m'\u001b[39;49m\u001b[39mgroup\u001b[39;49m\u001b[39m'\u001b[39;49m, group)\n\u001b[1;32m   2230\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:1993\u001b[0m, in \u001b[0;36mDataset.set_field\u001b[0;34m(self, field_name, data)\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[39mif\u001b[39;00m type_data \u001b[39m!=\u001b[39m FIELD_TYPE_MAPPER[field_name]:\n\u001b[1;32m   1992\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInput type error for set_field\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1993\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_DatasetSetField(\n\u001b[1;32m   1994\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1995\u001b[0m     c_str(field_name),\n\u001b[1;32m   1996\u001b[0m     ptr_data,\n\u001b[1;32m   1997\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(\u001b[39mlen\u001b[39;49m(data)),\n\u001b[1;32m   1998\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(type_data)))\n\u001b[1;32m   1999\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mversion \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   2000\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:125\u001b[0m, in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \n\u001b[1;32m    119\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39m    The return value from C API calls.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(_LIB\u001b[39m.\u001b[39mLGBM_GetLastError()\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;31mLightGBMError\u001b[0m: Sum of query counts is not same with #data"
     ]
    }
   ],
   "source": [
    "for i in range(0,9):\n",
    "    model = train_model( i )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5379260422831995\n",
      "0.5544787382727367\n",
      "0.5480938037545099\n",
      "0.5544980090490688\n",
      "0.5559050126736478\n",
      "0.5583576956894686\n",
      "0.5484790388984\n",
      "0.5628604026118849\n",
      "0.5408063583296453\n",
      "CPU times: user 14min 33s, sys: 3min 6s, total: 17min 39s\n",
      "Wall time: 3min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for validate_id in range(9):\n",
    "    # fit training data\n",
    "    X_path = project_root_path + '/dataset/train_features/train_X_' + str(validate_id) + '.pickle'\n",
    "    y_path = project_root_path + '/dataset/train_features/train_y_' + str(validate_id) + '.pickle'\n",
    "    with open( X_path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    with open( y_path, 'rb') as f:\n",
    "        y = pickle.load(f)\n",
    "\n",
    "    X_sessions = np.array_split(X, len(X)//n_train_sample)\n",
    "    y_sessions = np.array_split(y, len(y)//n_train_sample)\n",
    "    bst = lgb.Booster(model_file='../../model/lgbm_7')\n",
    "    print(MRR( X_sessions, y_sessions, bst))\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x2b56e4460>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst = lgb.Booster(model_file='../../model/lgbm_8')\n",
    "bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [04:42<00:00, 177.30it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "with open('../../dataset/test_leaderboard_uniq_sessions') as f:\n",
    "    for line in tqdm(f.readlines()[1:]):\n",
    "        session_id = int(line) \n",
    "        results.extend(predict_session(bst, session_id ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../result/lgbm_train7.csv', 'w') as f:\n",
    "    f.write('session_id,item_id,rank\\n')\n",
    "    f.write('\\n'.join(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
