{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import gc\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_root_path = '/content/drive/MyDrive/NCCU1102/WSM/proj3/RecSys-Dressipi/'\n",
    "project_root_path = '../..'\n",
    "n_train_sample = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model( i ):\n",
    "    # fit training data\n",
    "    X_path = project_root_path + '/dataset/train_features/train_X_' + str(i) + '.pickle'\n",
    "    y_path = project_root_path + '/dataset/train_features/train_y_' + str(i) + '.pickle'\n",
    "    with open( X_path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    with open( y_path, 'rb') as f:\n",
    "        y = pickle.load(f)\n",
    "\n",
    "    query_train = [n_train_sample] * (len(X)//n_train_sample)\n",
    "\n",
    "    print(\"Starting training... train_\" + str(i) )\n",
    "    start_time = time.time()\n",
    "    gbm = lgb.LGBMRanker(device = 'cpu')\n",
    "    if i == 0:\n",
    "        gbm.fit(X, y, group=query_train)\n",
    "    else:\n",
    "        gbm.fit(X, y, group=query_train, init_model='../../model/lgbm/lgbm_' + str(i-1))\n",
    "    gbm.booster_.save_model('../../model/lgbm/lgbm_' + str(i))\n",
    "    print(\"Training finished \" + str(time.time() - start_time))\n",
    "    \n",
    "    return gbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MRR( X_sessions, y_sessions, y_preds ):\n",
    "    score = []\n",
    "    for X, y, pred in zip( X_sessions, y_sessions, y_preds ):\n",
    "        top100_index = np.argsort(pred)[-100:]\n",
    "        rank_result = []\n",
    "        flag = False\n",
    "        for count, index in enumerate(top100_index[::-1]):\n",
    "            if y[index] == 1:\n",
    "                score.append(1/(count+1))\n",
    "                flag = True\n",
    "                break\n",
    "        if not flag:\n",
    "            score.append(0)\n",
    "    return np.mean(score)\n",
    "\n",
    "def pred2rank_result( session_id, X, pred ):\n",
    "    top100_index = np.argsort(pred)[-100:]\n",
    "    rank_result = []\n",
    "    for count, index in enumerate(top100_index[::-1]):\n",
    "        row = ','.join([str(session_id), str(int(X[index][0])), str(count+1)])\n",
    "        rank_result.append(row)\n",
    "    return rank_result\n",
    "\n",
    "def predict_session( gbm, session_id ):\n",
    "    with open('../../dataset/test_features/test_X_' + str(session_id) + '.pickle', 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    pred = gbm.predict(X)\n",
    "    return pred2rank_result( session_id, X, pred )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training... train_0\n",
      "Training finished 13.93949818611145\n",
      "Starting training... train_1\n",
      "Training finished 11.393312454223633\n",
      "Starting training... train_2\n",
      "Training finished 13.184983968734741\n",
      "Starting training... train_3\n",
      "Training finished 13.30923342704773\n",
      "Starting training... train_4\n",
      "Training finished 15.112048149108887\n",
      "Starting training... train_5\n",
      "Training finished 16.508822679519653\n",
      "Starting training... train_6\n",
      "Training finished 18.239848852157593\n",
      "Starting training... train_7\n",
      "Training finished 24.896216869354248\n",
      "Starting training... train_8\n",
      "Training finished 4.266885042190552\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    model = train_model( i )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46994645260165346\n",
      "0.4689435812922673\n",
      "CPU times: user 42min 2s, sys: 4.21 s, total: 42min 6s\n",
      "Wall time: 3min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bst = lgb.Booster(model_file='../../model/lgbm/lgbm_31')\n",
    "for validate_id in range(8,10):\n",
    "    # fit training data\n",
    "    X_path = project_root_path + '/dataset/train_features/train_X_' + str(validate_id) + '.pickle'\n",
    "    y_path = project_root_path + '/dataset/train_features/train_y_' + str(validate_id) + '.pickle'\n",
    "    with open( X_path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    with open( y_path, 'rb') as f:\n",
    "        y = pickle.load(f)\n",
    "\n",
    "    X_sessions = np.array_split(X, len(X)//n_train_sample)\n",
    "    y_sessions = np.array_split(y, len(y)//n_train_sample)\n",
    "\n",
    "    del X\n",
    "    del y\n",
    "    gc.collect()\n",
    "\n",
    "    y_preds = [bst.predict(X_session) for X_session in X_sessions]\n",
    "    print(MRR( X_sessions, y_sessions, y_preds))\n",
    "    del X_sessions\n",
    "    del y_sessions\n",
    "    del y_preds\n",
    "    gc.collect()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7f25085d2440>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst = lgb.Booster(model_file='../../model/lgbm/lgbm_8')\n",
    "bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [02:43<00:00, 304.94it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "with open('../../dataset/test_leaderboard_uniq_sessions') as f:\n",
    "    for line in tqdm(f.readlines()[1:]):\n",
    "        session_id = int(line) \n",
    "        results.extend(predict_session(bst, session_id ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../result/lgbm_train8_2021-5_newCF.csv', 'w') as f:\n",
    "    f.write('session_id,item_id,rank\\n')\n",
    "    f.write('\\n'.join(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
